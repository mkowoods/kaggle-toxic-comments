{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./input/train.csv\")\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127572, 8)\n",
      "(31999, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create train and Test Datasets\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "test = data[~msk]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_vec(df, column_name):\n",
    "    return df[[column_name]].as_matrix().reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=4, ngram_range=(1,2), stop_words='english', lowercase=True, binary=False)),\n",
    "    ('clf', SGDClassifier(loss='log', n_jobs=-1, max_iter = 1000, tol = 1e-3)),\n",
    "    #('clf', LogisticRegression(C = 0.8))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### toxic ####################\n",
      "\n",
      "0.5\n",
      "(24536,) (24536,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.96     28973\n",
      "          1       0.99      0.25      0.40      3026\n",
      "\n",
      "avg / total       0.93      0.93      0.91     31999\n",
      "\n",
      "[[28966     7]\n",
      " [ 2275   751]]\n",
      "0.954919899556\n",
      "########################################\n",
      "\n",
      "########### severe_toxic ####################\n",
      "\n",
      "0.5\n",
      "(2556,) (2556,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99     31682\n",
      "          1       0.42      0.02      0.03       317\n",
      "\n",
      "avg / total       0.98      0.99      0.99     31999\n",
      "\n",
      "[[31675     7]\n",
      " [  312     5]]\n",
      "0.984964245438\n",
      "########################################\n",
      "\n",
      "########### obscene ####################\n",
      "\n",
      "0.5\n",
      "(13524,) (13524,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     30312\n",
      "          1       0.99      0.28      0.43      1687\n",
      "\n",
      "avg / total       0.96      0.96      0.95     31999\n",
      "\n",
      "[[30305     7]\n",
      " [ 1221   466]]\n",
      "0.978301059223\n",
      "########################################\n",
      "\n",
      "########### threat ####################\n",
      "\n",
      "0.5\n",
      "(788,) (788,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwoods/miniconda2/envs/kaggle-dog-breed-comp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     31915\n",
      "          1       0.00      0.00      0.00        84\n",
      "\n",
      "avg / total       0.99      1.00      1.00     31999\n",
      "\n",
      "[[31915     0]\n",
      " [   84     0]]\n",
      "0.971154965198\n",
      "########################################\n",
      "\n",
      "########### insult ####################\n",
      "\n",
      "0.5\n",
      "(12668,) (12668,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98     30456\n",
      "          1       0.91      0.20      0.33      1543\n",
      "\n",
      "avg / total       0.96      0.96      0.95     31999\n",
      "\n",
      "[[30424    32]\n",
      " [ 1236   307]]\n",
      "0.967242725862\n",
      "########################################\n",
      "\n",
      "########### identity_hate ####################\n",
      "\n",
      "0.5\n",
      "(2250,) (2250,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     31719\n",
      "          1       0.00      0.00      0.00       280\n",
      "\n",
      "avg / total       0.98      0.99      0.99     31999\n",
      "\n",
      "[[31719     0]\n",
      " [  280     0]]\n",
      "0.966452227822\n",
      "########################################\n",
      "\n",
      "0.97050585385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwoods/miniconda2/envs/kaggle-dog-breed-comp/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "for label in LABELS:\n",
    "    print(\"########### %s ####################\\n\"%(label))\n",
    "    \n",
    "    y_train = get_y_vec(df = train, column_name=label)\n",
    "    X_train = train[['comment_text']].as_matrix().reshape((-1,))\n",
    "    \n",
    "    y_test = get_y_vec(df = test, column_name=label)\n",
    "    X_test = test[['comment_text']].as_matrix().reshape((-1,))\n",
    "    \n",
    "    clf = text_clf.fit(X=X_train, y=y_train)\n",
    "    y_ = clf.predict_proba(X_test)\n",
    "    y_bin = y_[:,1] > 0.35\n",
    "    print(classification_report(y_test, y_bin))\n",
    "    print(confusion_matrix(y_test, y_bin))\n",
    "    roc = roc_auc_score(y_test, y_[:, 1])\n",
    "    print(roc)\n",
    "    roc_scores.append(roc)\n",
    "    print(\"########################################\\n\")\n",
    "print(sum(roc_scores)/len(roc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = submission[['comment_text']].as_matrix().reshape((-1,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### toxic ####################\n",
      "\n",
      "0.5\n",
      "(30588,) (30588,)\n",
      "########### severe_toxic ####################\n",
      "\n",
      "0.5\n",
      "(3190,) (3190,)\n",
      "########### obscene ####################\n",
      "\n",
      "0.5\n",
      "(16898,) (16898,)\n",
      "########### threat ####################\n",
      "\n",
      "0.5\n",
      "(956,) (956,)\n",
      "########### insult ####################\n",
      "\n",
      "0.5\n",
      "(15754,) (15754,)\n",
      "########### identity_hate ####################\n",
      "\n",
      "0.5\n",
      "(2810,) (2810,)\n"
     ]
    }
   ],
   "source": [
    "#Create a model on full data set:\n",
    "results = {}\n",
    "for label in ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']:\n",
    "    print(\"########### %s ####################\\n\"%(label))\n",
    "    y_train_bal, X_train_bal, y_test, X_test = build_balanced_classifier(train = data, test = None, label = label)\n",
    "    clf = text_clf.fit(X=X_train_bal, y=y_train_bal)\n",
    "    y_ = clf.predict_proba(X_submission)\n",
    "    results[label] = y_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']\n",
    "for  label in LABELS:\n",
    "    submission[label] = results[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  \\\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
      "\n",
      "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \n",
      "0  0.674154      0.034076  0.491013  0.005864  0.391845       0.023581  \n",
      "1  0.057150      0.008737  0.034132  0.004264  0.034122       0.008764  \n",
      "2  0.069053      0.008961  0.037025  0.004286  0.036915       0.008922  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ \"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\",\n",
       "       '== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
       "       '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland â€”  /  \"'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(submission[0:3])\n",
    "submission[0:3]['comment_text'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.674154</td>\n",
       "      <td>0.034076</td>\n",
       "      <td>0.491013</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.391845</td>\n",
       "      <td>0.023581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.057150</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.034132</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.034122</td>\n",
       "      <td>0.008764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.069053</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>0.008922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.041036</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.007497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.081241</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.036422</td>\n",
       "      <td>0.007717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.674154      0.034076  0.491013  0.005864  0.391845   \n",
       "1  0000247867823ef7  0.057150      0.008737  0.034132  0.004264  0.034122   \n",
       "2  00013b17ad220c46  0.069053      0.008961  0.037025  0.004286  0.036915   \n",
       "3  00017563c3f7919a  0.041036      0.007786  0.026333  0.003927  0.026221   \n",
       "4  00017695ad8997eb  0.081241      0.007832  0.038195  0.004001  0.036422   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.023581  \n",
       "1       0.008764  \n",
       "2       0.008922  \n",
       "3       0.007497  \n",
       "4       0.007717  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\"id\"]+LABELS\n",
    "print(headers)\n",
    "submission[headers].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "submission[headers].to_csv(\"./input/submissions-%s.csv\"%str(int(time.time())), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3wSoI-g9G9Sn",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#Adam optimizer, batch size of 64, Bi Directional  GRU, first try with deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "5pubcSJ1v-rp",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q keras\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "_pr-Mmn1wFKt",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#Upload files:\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# for fn in uploaded.keys():\n",
    "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#       name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "RLo0JZZAwREO",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#using google drive:\n",
    "#https://drive.google.com/open?id=1csHM7IpU3V-Swap3s83hP4hfygF_4noG\n",
    "\n",
    "#_NotebookApp.iopub_data_rate_limit = 1000000.0 * 100 #100x the default\n",
    "\n",
    "!pip install -q tqdm\n",
    "import tqdm\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "\n",
    "def download_file_from_google_drive(file_id = None, out_file_name = None):\n",
    "  assert file_id is not None and out_file_name is not None\n",
    "  auth.authenticate_user()\n",
    "  drive_service = build('drive', 'v3')\n",
    "  request = drive_service.files().get_media(fileId=file_id)\n",
    "  downloaded = io.BytesIO()\n",
    "  downloader = MediaIoBaseDownload(downloaded, request)\n",
    "  done = False\n",
    "  pbar = tqdm.tqdm(total=100, desc=out_file_name)\n",
    "\n",
    "  while done is False:\n",
    "    # _ is a placeholder for a progress object that we ignore.\n",
    "    # (Our file is small, so we skip reporting progress.)\n",
    "    status, done = downloader.next_chunk()\n",
    "    pbar.update(status.progress() * 100)\n",
    "    #print(\"Downloaded: \", int(status.progress() * 100))\n",
    "\n",
    "  downloaded.seek(0)\n",
    "  #print('Downloaded file contents are: {}'.format(downloaded.read()[:10]))\n",
    "  with open(out_file_name, 'wb') as out:\n",
    "    out.write(downloaded.read())\n",
    "  print(\"Data downloaded to: \", out_file_name)\n",
    "  return out_file_name\n",
    " \n",
    "\n",
    "def save_file_to_google_drive(local_filename, dest_filename, mimetype = 'application/octet-stream'):\n",
    "  auth.authenticate_user()\n",
    "  drive_service = build('drive', 'v3')\n",
    "\n",
    "  file_metadata = {\n",
    "    'name': dest_filename,\n",
    "    'mimeType': mimetype\n",
    "  }\n",
    "  media = MediaFileUpload(local_filename, \n",
    "                          mimetype=mimetype,\n",
    "                          resumable=True)\n",
    "  created = drive_service.files().create(body=file_metadata,\n",
    "                                         media_body=media,\n",
    "                                         fields='id').execute()\n",
    "  print('File ID: {}'.format(created.get('id')))\n",
    "  return created.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "PEVBeQjb0vhQ",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 55.0
      },
      {
       "item_id": 56.0
      },
      {
       "item_id": 104.0
      },
      {
       "item_id": 105.0
      },
      {
       "item_id": 106.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 294.0
    },
    "outputId": "d9c4f1b5-f28c-4f5c-943e-a60188fccb98",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.520274022983E12,
     "user_tz": -60.0,
     "elapsed": 90160.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.csv.zip: 2715.758477741821it [00:44, 97.75it/s]\n",
      "test.csv.zip:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to:  train.csv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "test.csv.zip:   2%|â–         | 2.133228206336118/100 [00:02<01:54,  1.17s/it]\u001b[A\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 148, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "test.csv.zip: 2406.0196910493432it [00:44, 132.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to:  test.csv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_file_from_google_drive('1csHM7IpU3V-Swap3s83hP4hfygF_4noG', 'train.csv.zip')\n",
    "download_file_from_google_drive('1o8Abgh9QBG30WakYhD7k13qubm4iqytg', 'test.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "QGwgIvow42XZ",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VTFXYceb1UgU",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv.zip', compression = 'zip')\n",
    "test = pd.read_csv('test.csv.zip', compression = 'zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qCOzFPee-R1E",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 500 #should analyze the distribution of sequences to determine right value\n",
    "max_features = 75000\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Kzibix0mC0j1",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 2.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 69.0
    },
    "outputId": "4d6a4eb4-3eea-4b92-a528-d84ba21416ad",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.520274056168E12,
     "user_tz": -60.0,
     "elapsed": 6089.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "Max Length of sequence 500\n",
      "Max Index 74999\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(\"Max Length of sequence\", max([len(seq) for seq in X_train]))\n",
    "print(\"Max Index\", max([max(seq) for seq in X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "rQlok9mxDJzR",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            local_fname = \"test_model.h5\"\n",
    "            y_pred = self.model.predict(self.X_val, verbose=1)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            val_loss = logs.get(\"val_loss\", \"null\")\n",
    "            val_acc = logs.get(\"val_acc\", \"null\")\n",
    "            fname = \"model-roc-{roc}-val_loss-{val_loss}-val_acc-{val_acc}-epoch-{epoch}.h5\".format(roc=score, val_loss = val_loss, val_acc = val_acc, epoch=epoch)\n",
    "            print(\"\\n Saving model to local directory as:\", local_fname)\n",
    "            self.model.save(local_fname)\n",
    "            print(\"\\n save to local complete\")\n",
    "            print(\"\\n starting upload to google drive\", fname)\n",
    "            fid = save_file_to_google_drive(local_fname, fname)\n",
    "            print(\"\\n upload completed: \", fid)\n",
    "            \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        if epoch % 200 == 0:\n",
    "            print('\\n Starting ROC Eval on rand 1000 sample')\n",
    "            sample = np.random.randint(X_val.shape[0], size = 1000)\n",
    "            y_pred = self.model.predict(self.X_val[sample], verbose=1)\n",
    "            y_val = self.y_val[sample]\n",
    "            score = roc_auc_score(y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qs5yBknTFFPn",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(num_features, embed_size)(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "DhiPx0h_GL_1",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "e899e362-8b05-42b2-98f0-ba51168abec8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.520281356018E12,
     "user_tz": -60.0,
     "elapsed": 1104.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 6\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(X_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "K1YohWaRVWvC",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 35.0
      },
      {
       "item_id": 36.0
      },
      {
       "item_id": 37.0
      },
      {
       "item_id": 38.0
      },
      {
       "item_id": 501.0
      },
      {
       "item_id": 863.0
      },
      {
       "item_id": 1221.0
      },
      {
       "item_id": 1623.0
      },
      {
       "item_id": 2063.0
      },
      {
       "item_id": 2425.0
      },
      {
       "item_id": 2771.0
      },
      {
       "item_id": 2976.0
      },
      {
       "item_id": 2977.0
      },
      {
       "item_id": 2978.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 2959.0
    },
    "outputId": "8e9dc6c3-58a1-4655-edd1-1ce81b550d55",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.520284846142E12,
     "user_tz": -60.0,
     "elapsed": 3488963.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/6\n",
      "    64/151592 [..............................] - ETA: 3:18:11 - loss: 0.0442 - acc: 0.9844\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 10s 10ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.981238 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (10.144026). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r   128/151592 [..............................] - ETA: 5:26:21 - loss: 0.0412 - acc: 0.9870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (5.073380). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12864/151592 [=>............................] - ETA: 51:35 - loss: 0.0378 - acc: 0.9857\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 201 - score: 0.985850 \n",
      "\n",
      " 25664/151592 [====>.........................] - ETA: 46:18 - loss: 0.0381 - acc: 0.9855\n",
      " Starting ROC Eval on rand 1000 sample\n",
      " 960/1000 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 401 - score: 0.985650 \n",
      "\n",
      " 38464/151592 [======>.......................] - ETA: 41:30 - loss: 0.0389 - acc: 0.9852\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 601 - score: 0.982120 \n",
      "\n",
      " 46528/151592 [========>.....................] - ETA: 38:41 - loss: 0.0397 - acc: 0.9849"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51264/151592 [=========>....................] - ETA: 36:50 - loss: 0.0397 - acc: 0.9848\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 801 - score: 0.960177 \n",
      "\n",
      " 64064/151592 [===========>..................] - ETA: 32:09 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1001 - score: 0.983450 \n",
      "\n",
      " 65216/151592 [===========>..................] - ETA: 31:54 - loss: 0.0404 - acc: 0.9845"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76864/151592 [==============>...............] - ETA: 27:28 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1201 - score: 0.985478 \n",
      "\n",
      " 89664/151592 [================>.............] - ETA: 22:45 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1401 - score: 0.977576 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102464/151592 [===================>..........] - ETA: 18:02 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1601 - score: 0.981660 \n",
      "\n",
      "115264/151592 [=====================>........] - ETA: 13:20 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      " 960/1000 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1801 - score: 0.987410 \n",
      "\n",
      "128064/151592 [========================>.....] - ETA: 8:37 - loss: 0.0405 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 2001 - score: 0.989228 \n",
      "\n",
      "136128/151592 [=========================>....] - ETA: 5:40 - loss: 0.0405 - acc: 0.9845"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140864/151592 [==========================>...] - ETA: 3:56 - loss: 0.0404 - acc: 0.9845\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 2201 - score: 0.983656 \n",
      "\n",
      "151592/151592 [==============================] - 3376s 22ms/step - loss: 0.0404 - acc: 0.9845 - val_loss: 0.0461 - val_acc: 0.9819\n",
      "2656/7979 [========>.....................] - ETA: 47s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7979/7979 [==============================] - 72s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.985954 \n",
      "\n",
      "\n",
      " Saving model to local directory as: test_model.h5\n",
      "\n",
      " save to local complete\n",
      "\n",
      " starting upload to google drive\n",
      "File ID: 1-3hIYWm1vC6An3mx7pJHUrdVfLkXX3g9\n",
      "\n",
      " upload completed:  1-3hIYWm1vC6An3mx7pJHUrdVfLkXX3g9\n",
      "Epoch 2/6\n",
      "    64/151592 [..............................] - ETA: 48:42 - loss: 0.0445 - acc: 0.9818\n",
      " Starting ROC Eval on rand 1000 sample\n",
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988937 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (9.190848). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-5bac0b6d314d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n\u001b[0;32m----> 4\u001b[0;31m                  callbacks=[RocAuc])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.load_weights(\"model.h5\")\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "-00svZrAntQU",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    },
    "outputId": "38f91f25-27f7-414a-bbea-4b5efdd3d400",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.52027864268E12,
     "user_tz": -60.0,
     "elapsed": 23387.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1o4snyfur9XHRCh-H51oxC-PGRNwJ4SVU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#'model-roc-0.978691-val_loss-0.0488-val_acc-0.9815.h5'\n",
    "# Upload the file to Drive. See:\n",
    "#\n",
    "# https://developers.google.com/drive/v3/reference/files/create\n",
    "# https://developers.google.com/drive/v3/web/manage-uploads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "nuVcGjupqncx",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 218.0
    },
    "outputId": "68cbdf61-3c61-40c7-bfd6-c342267c672c",
    "executionInfo": {
     "status": "error",
     "timestamp": 1.520285239363E12,
     "user_tz": -60.0,
     "elapsed": 79445.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-38a33a3920e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"toxic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"severe_toxic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"obscene\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"threat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"insult\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"identity_hate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "o9oZwiO3s0x5",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    "#y_pred.shape\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for idx, label in enumerate(labels):\n",
    "  test[label] = y_pred[:, idx]\n",
    "test.head()\n",
    "headers = [\"id\"]+labels\n",
    "test[headers].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "UetX4xuLs3JR",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     },
     "output_extras": [
      {
       "item_id": 1.0
      },
      {
       "item_id": 2.0
      }
     ],
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "9dc8d848-95f5-4e94-b122-ad4fae3e04b6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.520285829372E12,
     "user_tz": -60.0,
     "elapsed": 2836.0,
     "user": {
      "displayName": "m w",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108090985198282462897"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ID: 1Ru1HHYGXNVvIb3Rm-mnU8FIIx1hxW7R5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1Ru1HHYGXNVvIb3Rm-mnU8FIIx1hxW7R5'"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file_to_google_drive(\"submission.csv\", \"030518-lab-1-submission.csv\", mimetype=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "gz9RJBb4GL2g",
    "colab_type": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0.0
     }
    }
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "kaggle-toxic-comment 030518 Lab 1.ipynb",
   "version": "0.3.2",
   "views": {},
   "default_view": {},
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

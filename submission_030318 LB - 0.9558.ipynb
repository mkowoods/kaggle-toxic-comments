{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from subprocess import check_output\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./input/train.csv\")\n",
    "LABELS = ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127572, 8)\n",
      "(31999, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create train and Test Datasets\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "test = data[~msk]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Baseline ROC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_vec(df, column_name):\n",
    "    return df[[column_name]].as_matrix().reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive bayes classifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='log', max_iter=1000, tol=1e-3)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build function to get balanced samples\n",
    "def build_balanced_classifier(train, test = None, label = None):\n",
    "    y_ = get_y_vec(df = train, column_name=label)\n",
    "    pos_cases = (y_ == 1)\n",
    "    num_pos_cases = pos_cases.sum()\n",
    "    idx_desc = np.argsort(-y_) #sort indices high to low so positive cases are at the front\n",
    "    balance_samples = idx_desc[:2*num_pos_cases] #extract 2x the num pos cases so now 50/50 pos/neg\n",
    "    print(y_[balance_samples].mean()) #confirm probability\n",
    "    y_train_bal = y_[balance_samples]\n",
    "    X_train_bal = train[['comment_text']].as_matrix().reshape((-1,))\n",
    "    X_train_bal = X_train_bal[balance_samples]\n",
    "    print(y_train_bal.shape, X_train_bal.shape)\n",
    "    \n",
    "    y_test, X_test = None, None\n",
    "    if test is not None:\n",
    "        y_test = get_y_vec(df = test, column_name=label)\n",
    "        X_test = test[['comment_text']].as_matrix().reshape((-1,))    \n",
    "    return y_train_bal, X_train_bal, y_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### toxic ####################\n",
      "\n",
      "0.5\n",
      "(24536,) (24536,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.90      0.94     28973\n",
      "          1       0.48      0.86      0.61      3026\n",
      "\n",
      "avg / total       0.94      0.90      0.91     31999\n",
      "\n",
      "[[26121  2852]\n",
      " [  417  2609]]\n",
      "0.950508306512\n",
      "########################################\n",
      "\n",
      "########### severe_toxic ####################\n",
      "\n",
      "0.5\n",
      "(2556,) (2556,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.95      0.97     31682\n",
      "          1       0.15      0.96      0.27       317\n",
      "\n",
      "avg / total       0.99      0.95      0.97     31999\n",
      "\n",
      "[[30016  1666]\n",
      " [   14   303]]\n",
      "0.983262894255\n",
      "########################################\n",
      "\n",
      "########### obscene ####################\n",
      "\n",
      "0.5\n",
      "(13524,) (13524,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.93      0.96     30312\n",
      "          1       0.43      0.87      0.57      1687\n",
      "\n",
      "avg / total       0.96      0.93      0.94     31999\n",
      "\n",
      "[[28326  1986]\n",
      " [  212  1475]]\n",
      "0.967308671891\n",
      "########################################\n",
      "\n",
      "########### threat ####################\n",
      "\n",
      "0.5\n",
      "(788,) (788,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.92      0.96     31915\n",
      "          1       0.03      0.92      0.05        84\n",
      "\n",
      "avg / total       1.00      0.92      0.95     31999\n",
      "\n",
      "[[29262  2653]\n",
      " [    7    77]]\n",
      "0.979323612572\n",
      "########################################\n",
      "\n",
      "########### insult ####################\n",
      "\n",
      "0.5\n",
      "(12668,) (12668,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.92      0.95     30456\n",
      "          1       0.35      0.89      0.50      1543\n",
      "\n",
      "avg / total       0.96      0.91      0.93     31999\n",
      "\n",
      "[[27879  2577]\n",
      " [  170  1373]]\n",
      "0.963062699931\n",
      "########################################\n",
      "\n",
      "########### identity_hate ####################\n",
      "\n",
      "0.5\n",
      "(2250,) (2250,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.91      0.95     31719\n",
      "          1       0.08      0.90      0.15       280\n",
      "\n",
      "avg / total       0.99      0.91      0.95     31999\n",
      "\n",
      "[[28976  2743]\n",
      " [   27   253]]\n",
      "0.966182166615\n",
      "########################################\n",
      "\n",
      "0.968274725296\n"
     ]
    }
   ],
   "source": [
    "roc_scores = []\n",
    "for label in LABELS:\n",
    "    print(\"########### %s ####################\\n\"%(label))\n",
    "    y_train_bal, X_train_bal, y_test, X_test = build_balanced_classifier(train, test, label)\n",
    "    clf = text_clf.fit(X=X_train_bal, y=y_train_bal)\n",
    "    y_ = clf.predict_proba(X_test)\n",
    "    y_bin = y_[:,1] > 0.5\n",
    "    print(classification_report(y_test, y_bin))\n",
    "    print(confusion_matrix(y_test, y_bin))\n",
    "    roc = roc_auc_score(y_test, y_[:, 1])\n",
    "    print(roc)\n",
    "    roc_scores.append(roc)\n",
    "    print(\"########################################\\n\")\n",
    "print(sum(roc_scores)/len(roc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = submission[['comment_text']].as_matrix().reshape((-1,))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### toxic ####################\n",
      "\n",
      "0.5\n",
      "(30588,) (30588,)\n",
      "########### severe_toxic ####################\n",
      "\n",
      "0.5\n",
      "(3190,) (3190,)\n",
      "########### obscene ####################\n",
      "\n",
      "0.5\n",
      "(16898,) (16898,)\n",
      "########### threat ####################\n",
      "\n",
      "0.5\n",
      "(956,) (956,)\n",
      "########### insult ####################\n",
      "\n",
      "0.5\n",
      "(15754,) (15754,)\n",
      "########### identity_hate ####################\n",
      "\n",
      "0.5\n",
      "(2810,) (2810,)\n"
     ]
    }
   ],
   "source": [
    "#Create a model on full data set:\n",
    "results = {}\n",
    "for label in ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']:\n",
    "    print(\"########### %s ####################\\n\"%(label))\n",
    "    y_train_bal, X_train_bal, y_test, X_test = build_balanced_classifier(train = data, test = None, label = label)\n",
    "    clf = text_clf.fit(X=X_train_bal, y=y_train_bal)\n",
    "    y_ = clf.predict_proba(X_submission)\n",
    "    results[label] = y_[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['toxic', 'severe_toxic', 'obscene','threat', 'insult', 'identity_hate']\n",
    "for  label in LABELS:\n",
    "    submission[label] = results[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  \\\n",
      "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
      "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
      "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
      "\n",
      "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \n",
      "0  0.989822      0.970913  0.988816  0.981573  0.987518       0.984143  \n",
      "1  0.116129      0.064984  0.106774  0.024232  0.136345       0.159588  \n",
      "2  0.167684      0.058812  0.151794  0.117047  0.146060       0.138308  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ \"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\",\n",
       "       '== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
       "       '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(submission[0:3])\n",
    "submission[0:3]['comment_text'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.989822</td>\n",
       "      <td>0.970913</td>\n",
       "      <td>0.988816</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.987518</td>\n",
       "      <td>0.984143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.116129</td>\n",
       "      <td>0.064984</td>\n",
       "      <td>0.106774</td>\n",
       "      <td>0.024232</td>\n",
       "      <td>0.136345</td>\n",
       "      <td>0.159588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.167684</td>\n",
       "      <td>0.058812</td>\n",
       "      <td>0.151794</td>\n",
       "      <td>0.117047</td>\n",
       "      <td>0.146060</td>\n",
       "      <td>0.138308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.074261</td>\n",
       "      <td>0.085070</td>\n",
       "      <td>0.084348</td>\n",
       "      <td>0.070966</td>\n",
       "      <td>0.079823</td>\n",
       "      <td>0.055560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>0.215978</td>\n",
       "      <td>0.275876</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.255797</td>\n",
       "      <td>0.195586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.989822      0.970913  0.988816  0.981573  0.987518   \n",
       "1  0000247867823ef7  0.116129      0.064984  0.106774  0.024232  0.136345   \n",
       "2  00013b17ad220c46  0.167684      0.058812  0.151794  0.117047  0.146060   \n",
       "3  00017563c3f7919a  0.074261      0.085070  0.084348  0.070966  0.079823   \n",
       "4  00017695ad8997eb  0.328461      0.215978  0.275876  0.089304  0.255797   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.984143  \n",
       "1       0.159588  \n",
       "2       0.138308  \n",
       "3       0.055560  \n",
       "4       0.195586  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\"id\"]+LABELS\n",
    "print(headers)\n",
    "submission[headers].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "submission[headers].to_csv(\"./input/submissions-%s.csv\"%str(int(time.time())), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
